Once that first blush fades, it becomes clear that ChatGPT doesn’t actually
know anything—instead, it outputs compositions that simulate knowledge
through persuasive structure.
    --Ian Bogost, "Generative Art Is Stupid" (_The Atlantic,_ 2023-01-14)
%
ChatGPT is autocomplete on steroids. [paraphrased]
    --Gary Marcus
%
Q to ChatGPT: Where is New Scotland Yard?
A: New Scotland Yard is located at 8-10 Broadway, Westminster, London,
   England. It was the headquarters of the Metropolitan Police Service
   (MPS) from 1890 to 1967, and the name "New Scotland Yard" was also used
   as a metonym for the MPS itself. However, since 2017, the MPS moved to a
   new location, Metropolitan Police Service at Curtis Green, London,
   England.
(Actually, New Scotland Yard was at Embankment from 1890 to 1967, 8-10
Broadway from 1967 to 2017, and moved back to Embankment, to the Curtis
Green building adjacent to the previous headquarters, in 2017.)
%
Our mission is to ensure that artificial general intelligence benefits all
of humanity.
    --OpenAI.com, a company that does machine learning, not AGI
%
This [ChatGPT] kind of artificial intelligence we're talking about right
now can sometimes lead to something we call hallucination. This then
expresses itself in such a way that a machine provides a convincing but
completely made-up answer.
    --Prabhakar Raghavan, head of Google Search
%
Think of ChatGPT as a blurry jpeg of all the text on the Web. It retains
much of the information on the Web, in the same way that a jpeg retains
much of the information of a higher-resolution image, but, if you’re
looking for an exact sequence of bits, you won’t find it; all you will ever
get is an approximation. But, because the approximation is presented in the
form of grammatical text, which ChatGPT excels at creating, it’s usually
acceptable. You’re still looking at a blurry jpeg, but the blurriness
occurs in a way that doesn’t make the picture as a whole look less sharp.
    --Ted Chiang, _The New Yorker,_ 2023-02-09
%
The fact that ChatGPT rephrases material from the Web instead of quoting it
word for word makes it seem like a student expressing ideas in her own
words, rather than simply regurgitating what she’s read; it creates the
illusion that ChatGPT understands the material. In human students, rote
memorization isn’t an indicator of genuine learning, so ChatGPT’s inability
to produce exact quotes from Web pages is precisely what makes us think
that it has learned something. When we’re dealing with sequences of words,
lossy compression looks smarter than lossless compression.
    --Ted Chiang, _The New Yorker,_ 2023-02-09
%
  Will letting a large language model handle the boilerplate allow writers to
focus their attention on the really creative parts?
  Obviously, no one can speak for all writers, but let me make the argument
that starting with a blurry copy of unoriginal work isn’t a good way to
create original work....
   There’s nothing magical or mystical about writing, but it involves more
than placing an existing document on an unreliable photocopier and pressing
the Print button.
    --Ted Chiang, _The New Yorker,_ 2023-02-09
